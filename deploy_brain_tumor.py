# -*- coding: utf-8 -*-
"""Deploy brain_tumor

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18lnKRQIhI0ukhZcEkaAWdoz6u824w7Mn

# Libraries
"""

!pip install anvil-uplink

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 
import requests
import numpy as np
import matplotlib.pyplot as plt
import cv2
import seaborn as sns
import tensorflow as tf
import anvil.media
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.utils import to_categorical, image_dataset_from_directory
from tensorflow.keras.models import load_model 
from sklearn.metrics import confusion_matrix
from PIL import Image
import pickle
import anvil.server

anvil.server.connect("FUQIFI2NFZ3G35H4ZQIU6GGW-JISZ5AVAEI4CDUQA")

"""# Data loading"""

from google.colab import drive
drive.mount('/content/gdrive')

train_path = '/content/gdrive/MyDrive/Colab Notebooks/dataset/brain_tumor/Training'
test_path = '/content/gdrive/MyDrive/Colab Notebooks/dataset/brain_tumor/Testing'

classes = ['notumor', 'glioma', 'meningioma', 'pituitary']

train_dataset = image_dataset_from_directory(directory=train_path, label_mode='categorical', class_names=classes)
test_dataset = image_dataset_from_directory(directory=test_path, label_mode='categorical', class_names=classes)

model1 = load_model('/content/gdrive/MyDrive/Colab Notebooks/CNN_Modifikasi_1.h5')

"""# Model initialization"""

model = tf.keras.models.Sequential()

# Preprocessing 
model.add(layers.Resizing(height=128, width=128, interpolation='bilinear'))
model.add(layers.Rescaling(scale=1./255))

# Data Augmentation
model.add(layers.RandomFlip(mode='horizontal_and_vertical'))
model.add(layers.RandomRotation(factor=.2))

# First Convolution
model.add(layers.Conv2D(filters=64, kernel_size=(1,5)))
model.add(layers.Conv2D(filters=64, kernel_size=(5,1)))
model.add(layers.Activation('leaky_relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPool2D(pool_size=(2,2)))
model.add(layers.Dropout(.2))

# Second Convolution
model.add(layers.Conv2D(filters=64, kernel_size=(1,3)))
model.add(layers.Conv2D(filters=64, kernel_size=(3,1)))
model.add(layers.Activation('leaky_relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPool2D(pool_size=(2,2)))
model.add(layers.Dropout(.2))

# Third Convolution
model.add(layers.Conv2D(filters=64, kernel_size=(1,3)))
model.add(layers.Conv2D(filters=64, kernel_size=(3,1)))
model.add(layers.Activation('leaky_relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPool2D(pool_size=(2,2)))
model.add(layers.Dropout(.2))

# Feed forward
model.add(layers.Flatten())
model.add(layers.Dense(512))
model.add(layers.Activation('leaky_relu'))
model.add(layers.Dropout(.2))
model.add(layers.Dense(512))
model.add(layers.Activation('leaky_relu'))
model.add(layers.Dropout(.2))
model.add(layers.Dense(4))
model.add(layers.Activation('softmax'))

"""# Model training"""

optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, decay=1e-6)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)

model.save("sequential.h5")

"""# Model summary"""

model.summary()

"""# Training history plot"""

plt.figure(figsize=(12,5))
plt.subplot(122)

plt.subplot(1,2,1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['Training', 'Validation'])
plt.title('Model accuracy')

plt.subplot(1,2,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['Training', 'Validation'])
plt.title('Model loss')

plt.show()

"""# Confusion matrix plot"""

true_labels = []
predicted_labels = []

for x, y in test_dataset:
    true_labels.append(y)
    predicted_labels.append(model.predict(x))
    
true_labels = np.concatenate(true_labels, axis=0)
predicted_labels = np.concatenate(predicted_labels, axis=0)

true_labels_list = []
predicted_labels_list = [] 

for (tr_lbl, pr_lbl) in zip (true_labels, predicted_labels):
    true_labels_list.append(np.argmax(tr_lbl))
    predicted_labels_list.append(np.argmax(pr_lbl))
    
true_labels_list = np.array(true_labels_list)
predicted_labels_list = np.array(predicted_labels_list)

cf_matrix = confusion_matrix(y_true=true_labels_list, y_pred=predicted_labels_list, normalize='pred')

labels = ['No tumor', 'Glioma', 'Meningioma', 'Pituitary']

plt.figure(figsize=(7,5))

sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='.3f')

plt.ylabel('True classes')
yticks, _ = plt.yticks()
plt.yticks(ticks=yticks, labels=labels, rotation=45)

plt.xlabel('Predicted classes')
xticks, _ = plt.xticks()
plt.xticks(ticks=xticks, labels=labels, rotation=45)

plt.title('Confusion Matrixn\nNormalized over predictions')


plt.show()

"""# Predict on new data"""

brain_tumor = "/content/tes3.jpg"
brain_tumor_path = tf.keras.utils.get_file('tumor', origin=brain_tumor)

img = tf.keras.utils.load_img(
    brain_tumor
)
img_array = tf.keras.utils.img_to_array(img)
img_array = tf.expand_dims(img_array, 0) # Create a batch

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])

print(
    "This image most likely belongs to {} with a {:.2f} percent confidence."
    .format(classes[np.argmax(score)], 100 * np.max(score))
)

"""### APLIKASI"""

IMG_SIZE = 256
def prepare(img):
    img = cv2.resize(img, (256,256))
    imgs = np.array([img])
    return imgs.reshape(-1, IMG_SIZE, IMG_SIZE, 3)

def hitung(param):
    if np.argmax(param) == 0:
        return 'No Tumor'
    elif np.argmax(param) == 1:
        return 'Glioma'   
    elif np.argmax(param) == 2:
        return 'Meningioma'    
    else:
        return 'Pituitary'

def prediksi(img):
  yh = model1.predict(prepare(img))
  return hitung(yh)

@anvil.server.callable

def classify_image(file):
  with anvil.media.TempFile(file) as f:
    img = np.array(Image.open(f))
  hasil = prediksi(img)
  return hasil

"""### Anvil Server"""

anvil.server.wait_forever()